# Investigating Russian ‘Twitter Trolls’ using NLP

## Goal

In the last few years, Russia has emerged as a major player in social media based propaganda, utilizing platforms such as Twitter, Google, and Facebook to spread false or misleading information. Kremlin-linked ‘trolls’ have been found employing strategies such as [fabricating identities](https://www.vox.com/policy-and-politics/2017/10/19/16504510/ten-gop-twitter-russia) to spread false information, creating bots to artificially inflate popularity metrics such as follower counts and likes, and [buying ad space](https://www.nytimes.com/2017/11/01/us/politics/russia-2016-election-facebook.html) on platforms in order to spread ‘fake news.’

Twitter hasn’t been very forthcoming with details about Russian influence on their platform, and in fact, they wiped all Russia linked tweets and users without providing that information to the scientific community.  Luckily, a handful of third party twitter developers retained copies of those Kremlin-linked tweets, and [provided NBC with 200k of them](https://www.nbcnews.com/tech/social-media/now-available-more-200-000-deleted-russian-troll-tweets-n844731).

Extracting the semantic meaning from the tweets in this dataset is useful because it can be used for quicker and more in-depth investigations of the strategies employed by Russia for spreading false information and sowing discord.

## Modeling
Two forms of modeling were employed for extracting semantic meaning from these tweets—Latent Semantic Analysis(LSA) with KMeans clustering, and Latent Dirichlet allocation(LDA).

The vectorization process involved removing urls, fixing minor anomalies, removing words with no semantic value, generating unigrams and bigrams, and condensing duplicate references for entities such as Donald Trump and Hillary Clinton. This produced a corpus of ~6000 unique words.

An analysis of a singular value elbow plot generated by LSA with 50 topics indicated potential topic cutoffs of 3 and 17. Both values, as well as values of 50, 100, and 300, were tested with Kmeans cluster with centroid counts ranging from 3 to 50. The results were less than ideal, never producing a silhouette coefficient above .05 and generated highly unbalanced clusters. Manual inspection of the clusters also indicated inconsistent and uninterpretable results.

With clustering not being viable, the focus of the project shifted to topic modeling with LDA. A variety of topic counts were tested, but 15 was found to be the sweet spot of producing interpretable topics. These topics were used to analyze monthly spikes in tweeting activity by the trolls in response to particular events. See below for a visualization of this.

![](/images/lda_with_dates.png)

## Conclusions
As shown by the results of LSA testing, there was not a lot of signal in the vectorized tweets. However LDA was able to pick up on a bit of signal, and we were able to show that trolls sprang into action based off of notable world events.

One way to improve results could be more thorough pre-processing. For example, LDA result may possible improve if only nouns from the tweets are used.

The topics generated from this project could be used for further investigations on the dataset as a whole. Did particular users generally tweet about the same topics over time? Did particular topics obtain higher retweet and favorite counts?

____

Unfortunately this isn't the cleanest repository. As I attempted to work with new concepts and environments at the speed they were introduced, I didn't have the time to plan out the cleanest way to develop this project. If you have any questions on my ability to develop a clean repository, please feel free to reach out to me about production repositories I've worked on in the past.

[VSM Exploration](/VSM%20Exploration) contains many different notebooks attempting to cluster the tweet data.
The visualization mentioned above was generate via the [visualizations notebook](visualizations.ipynb)